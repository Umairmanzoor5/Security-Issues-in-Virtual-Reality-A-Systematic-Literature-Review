Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Abstract,Index Keywords,Funding Details,Language of Original Document,Document Type,Publication Stage,Open Access,Source,EID
"Chengoden R., Victor N., Huynh-The T., Yenduri G., Jhaveri R.H., Alazab M., Bhattacharya S., Hegde P., Maddikunta P.K.R., Gadekallu T.R.","57903496800;56175502600;56024804100;57223040078;55201717100;36661792200;55808089600;57424038400;58109115000;58072593700;","Metaverse for Healthcare: A Survey on Potential Applications, Challenges and Future Directions",2023,"IEEE Access","11",,,"12764","12794",,,"10.1109/ACCESS.2023.3241628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148472517&doi=10.1109%2fACCESS.2023.3241628&partnerID=40&md5=0862b665926d5c2d1c911bb7674a27ff","The rapid progress in digitalization and automation have led to an accelerated growth in healthcare, generating novel models that are creating new channels for rendering treatment at reduced cost. The Metaverse is an emerging technology in the digital space which has huge potential in healthcare, enabling realistic experiences to the patients as well as the medical practitioners. The Metaverse is a confluence of multiple enabling technologies such as artificial intelligence, virtual reality, augmented reality, internet of medical devices, robotics, quantum computing, etc. through which new directions for providing quality healthcare treatment and services can be explored. The amalgamation of these technologies ensures immersive, intimate and personalized patient care. It also provides adaptive intelligent solutions that eliminates the barriers between healthcare providers and receivers. This article provides a comprehensive review of the Metaverse for healthcare, emphasizing on the state of the art, the enabling technologies to adopt the Metaverse for healthcare, the potential applications, and the related projects. The issues in the adaptation of the Metaverse for healthcare applications are also identified and the plausible solutions are highlighted as part of future research directions. © 2013 IEEE.","Augmented reality; Biomedical equipment; Health care; Quantum computers; Cyber security; Digital space; Emerging technologies; Enabling technologies; Healthcare; Medical practitioner; Metaverses; New channels; On potentials; Reduced cost; Virtual reality",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85148472517
"Tricomi P.P., Nenna F., Pajola L., Conti M., Gamberi L.","57219175749;57218995768;57196020265;15019127200;58107530600;","You Can't Hide Behind Your Headset: User Profiling in Augmented and Virtual Reality",2023,"IEEE Access","11",,,"9859","9875",,,"10.1109/ACCESS.2023.3240071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148327782&doi=10.1109%2fACCESS.2023.3240071&partnerID=40&md5=c406ffcdd852899581027dad828fb86f","Augmented and Virtual Reality (AR and VR), collectively known as Extended Reality (XR), are increasingly gaining traction thanks to their technical advancement and the need for remote connections, recently accentuated by the pandemic. Remote surgery, telerobotics, and virtual offices are only some examples of their successes. As users interact with XR, they generate extensive behavioral data usually leveraged for measuring human activity, which could be used for profiling users' identities or personal information (e.g., gender). However, several factors affect the efficiency of profiling, such as the technology employed, the action taken, the mental workload, the presence of bias, and the sensors available. To date, no study has considered all of these factors together and in their entirety, limiting the current understanding of XR profiling. In this work, we provide a comprehensive study on user profiling in virtual technologies (i.e., AR, VR). Specifically, we employ machine learning on behavioral data (i.e., head, controllers, and eye data) to identify users and infer their individual attributes (i.e., age, gender). Toward this end, we propose a general framework that can potentially infer any personal information from any virtual scenarios. We test our framework on eleven generic actions (e.g., walking, searching, pointing) involving low and high mental loads, derived from two distinct use cases: an AR everyday application (34 participants) and VR robot teleoperation (35 participants). Our framework limits the burden of creating technology- and action-dependent algorithms, also reducing the experimental bias evidenced in previous work, providing a simple (yet effective) baseline for future works. We identified users up to 97% F1-score in VR and 80% in AR. Gender and Age inference was also facilitated in VR, reaching up to 82% and 90% F1-score, respectively. Through an in-depth analysis of sensors' impact, we found VR profiling resulting more effective than AR mainly because of the eye sensors' presence. © 2013 IEEE.","E-learning; Machine learning; User profile; Virtual reality; Augmented and virtual realities; Behavioral data; F1 scores; Machine-learning; Metaverses; Personal information; Privacy; Remote surgery; Technical advancement; User's profiling; Augmented reality",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85148327782
"Syed T.A., Jan S., Siddiqui M.S., Alzahrani A., Nadeem A., Ali A., Ullah A.","55204929000;56825229400;23096216800;57197006041;35183741600;57204889396;58000250500;","CAR-Tourist: An Integrity-Preserved Collaborative Augmented Reality Framework-Tourism as a Use-Case",2022,"Applied Sciences (Switzerland)","12","23","12022","","",,1,"10.3390/app122312022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143717675&doi=10.3390%2fapp122312022&partnerID=40&md5=bf7e94bd5b8624e2299e43d96e7e7d76","The unprecedented growth in Augmented Reality (AR) has captured the focus of researchers and the industrial sector. The development of AR applications and their implementation in various domains is broadening. One of the advancements in the field of AR is Collaborative AR, which provides ample opportunities for the members of a team to work on a particular project remotely. The various activities carried out remotely, in a collaborative fashion, are based on the active interaction and transmission of data and applications across a communication channel that constitutes a mesh of frequently interacting applications, thus providing a real feeling of working together physically in the purportedly same demographic area. However, in the integration of different roles, remotely working in collaborative AR has a great chance of being intruded upon and manipulated. Consequently, the intrusion may explore novel vulnerabilities to various sensitive collaborative projects. One of the security concerns for collaborative and interconnected remote applications is to have pristine environments, where the participants of the collaborative AR can reliably trust each other during the execution of the various processes. This paper presents an integrity-aware CAR-Tourist (Collaborative Augmented reality for Tourism) framework wherein the unauthorized user’s access is denied and the remote participants of the network are provided with a secure environment through the state-of-the-art Blockchain architecture. This study further provides a use-case implementation of a tourism application. Each tourist has the chance to hire a remote guide for collaborative guidance over a blockchain-trusted network. Moreover, the proposed framework is lightweight, as the only necessary communication between the tourist and guide is recorded in the blockchain network. Each user has to register on a permission blockchain to be allowed to perform certain activities on our proposed CAR-Tourist framework. The decentralized Blockchain approach provides a consensus mechanism based on which not every participant is free to intrude on ongoing communication. Thus, through the proposed framework, all the participants in the collaborative Augmented Reality will have the essential trust of working remotely without external intrusion. © 2022 by the authors.",,"20/17","English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85143717675
"Wei C., Lin W., Liang S., Chen M., Zheng Y., Liao X., Chen Z.","57740019800;57218916021;57739604300;57739604400;57209103498;57739477100;57034469300;","An All-In-One Multifunctional Touch Sensor with Carbon-Based Gradient Resistance Elements",2022,"Nano-Micro Letters","14","1","131","","",,6,"10.1007/s40820-022-00875-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131894495&doi=10.1007%2fs40820-022-00875-9&partnerID=40&md5=5fb3626c90f50d6f88c6be645fc983cc","Highlights: Carbon-based gradient resistance element structure is proposed for the construction of multifunctional touch sensor, which will promote wide detection and recognition range of multiple mechanical stimulations.Multifunctional touch sensor with gradient resistance element and two electrodes is demonstrated to eliminate signals crosstalk and prevent interference during position sensing for human–machine interactions.Biological sensing interface based on a deep-learning-assisted all-in-one multipoint touch sensor enables users to efficiently interact with virtual world. Abstract: Human–machine interactions using deep-learning methods are important in the research of virtual reality, augmented reality, and metaverse. Such research remains challenging as current interactive sensing interfaces for single-point or multipoint touch input are trapped by massive crossover electrodes, signal crosstalk, propagation delay, and demanding configuration requirements. Here, an all-in-one multipoint touch sensor (AIOM touch sensor) with only two electrodes is reported. The AIOM touch sensor is efficiently constructed by gradient resistance elements, which can highly adapt to diverse application-dependent configurations. Combined with deep learning method, the AIOM touch sensor can be utilized to recognize, learn, and memorize human–machine interactions. A biometric verification system is built based on the AIOM touch sensor, which achieves a high identification accuracy of over 98% and offers a promising hybrid cyber security against password leaking. Diversiform human–machine interactions, including freely playing piano music and programmatically controlling a drone, demonstrate the high stability, rapid response time, and excellent spatiotemporally dynamic resolution of the AIOM touch sensor, which will promote significant development of interactive sensing interfaces between fingertips and virtual objects.[Figure not available: see fulltext.] © 2022, The Author(s).","Augmented reality; Carbon; Deep learning; Electrodes; Functional materials; Hybrid materials; Carbon functional material; Carbon-based; Gradient resistance element; Human machine interaction; Multi-points; Multifunctional touch sensor; Paper based devices; Signal crosstalk; Touch sensors; Two electrodes; Virtual reality","22161142024, U1805261; A18A7b0058","English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85131894495
"Wang G., Badal A., Jia X., Maltz J.S., Mueller K., Myers K.J., Niu C., Vannier M., Yan P., Yu Z., Zeng R.","7407148134;22633591000;15132074800;6603895222;55366200700;7202026697;57202950909;24536157600;8346373300;57965768300;8610358700;","Development of metaverse for intelligent healthcare",2022,"Nature Machine Intelligence","4","11",,"922","929",,4,"10.1038/s42256-022-00549-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141902783&doi=10.1038%2fs42256-022-00549-6&partnerID=40&md5=acecc530cf6b8c160e9bab7cd532d12e","The metaverse integrates physical and virtual realities, enabling humans and their avatars to interact in an environment supported by technologies such as high-speed internet, virtual reality, augmented reality, mixed and extended reality, blockchain, digital twins and artificial intelligence (AI), all enriched by effectively unlimited data. The metaverse recently emerged as social media and entertainment platforms, but extension to healthcare could have a profound impact on clinical practice and human health. As a group of academic, industrial, clinical and regulatory researchers, we identify unique opportunities for metaverse approaches in the healthcare domain. A metaverse of ‘medical technology and AI’ (MeTAI) can facilitate the development, prototyping, evaluation, regulation, translation and refinement of AI-based medical practice, especially medical imaging-guided diagnosis and therapy. Here, we present metaverse use cases, including virtual comparative scanning, raw data sharing, augmented regulatory science and metaversed medical intervention. We discuss relevant issues on the ecosystem of the MeTAI metaverse including privacy, security and disparity. We also identify specific action items for coordinated efforts to build the MeTAI metaverse for improved healthcare quality, accessibility, cost-effectiveness and patient satisfaction. © 2022, Springer Nature Limited.","Augmented reality; Biomedical engineering; Diagnosis; Health care; Medical imaging; Virtual reality; Block-chain; Clinical practices; Healthcare domains; High speed internet; Human health; Medical practice; Medical technologies; Metaverses; Social entertainments; Social media; Cost effectiveness","R01CA227289, R01CA233888, R01CA237267, R01CA237269, R01EB026646, R01EB032716, R01HL151561, R37CA214639; ","English",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85141902783
"Dwivedi Y.K., Hughes L., Baabdullah A.M., Ribeiro-Navarrete S., Giannakis M., Al-Debei M.M., Dennehy D., Metri B., Buhalis D., Cheung C.M.K., Conboy K., Doyle R., Dubey R., Dutot V., Felix R., Goyal D.P., Gustafsson A., Hinsch C., Jebabli I., Janssen M., Kim Y.-G., Kim J., Koos S., Kreps D., Kshetri N., Kumar V., Ooi K.-B., Papagiannidis S., Pappas I.O., Polyviou A., Park S.-M., Pandey N., Queiroz M.M., Raman R., Rauschnabel P.A., Shirish A., Sigala M., Spanaki K., Wei-Han Tan G., Tiwari M.K., Viglia G., Wamba S.F.","35239818900;57205405210;57021768700;56676383100;22634489100;35753216500;55787347300;14071708100;6603014980;9434254900;18633741000;57218171817;36991875200;55509654200;57886314600;57812761700;57813352300;47461264600;56274399100;16199813000;35102430200;57211616143;57813352400;56111513900;9633912200;57812360800;14619509700;8848778400;55387371600;55604816600;57188729443;57813546700;56370773200;55808097300;56341892200;56323532000;6602603940;56319265200;57035671700;35427952100;41961835900;14833520200;","Metaverse beyond the hype: Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy",2022,"International Journal of Information Management","66",,"102542","","",,82,"10.1016/j.ijinfomgt.2022.102542","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134587952&doi=10.1016%2fj.ijinfomgt.2022.102542&partnerID=40&md5=838a76d17c1fe1d24c66375173ad5915","The metaverse has the potential to extend the physical world using augmented and virtual reality technologies allowing users to seamlessly interact within real and simulated environments using avatars and holograms. Virtual environments and immersive games (such as, Second Life, Fortnite, Roblox and VRChat) have been described as antecedents of the metaverse and offer some insight to the potential socio-economic impact of a fully functional persistent cross platform metaverse. Separating the hype and “meta…” rebranding from current reality is difficult, as “big tech” paints a picture of the transformative nature of the metaverse and how it will positively impact people in their work, leisure, and social interaction. The potential impact on the way we conduct business, interact with brands and others, and develop shared experiences is likely to be transformational as the distinct lines between physical and digital are likely to be somewhat blurred from current perceptions. However, although the technology and infrastructure does not yet exist to allow the development of new immersive virtual worlds at scale - one that our avatars could transcend across platforms, researchers are increasingly examining the transformative impact of the metaverse. Impacted sectors include marketing, education, healthcare as well as societal effects relating to social interaction factors from widespread adoption, and issues relating to trust, privacy, bias, disinformation, application of law as well as psychological aspects linked to addiction and impact on vulnerable people. This study examines these topics in detail by combining the informed narrative and multi-perspective approach from experts with varied disciplinary backgrounds on many aspects of the metaverse and its transformational impact. The paper concludes by proposing a future research agenda that is valuable for researchers, professionals and policy makers alike. © 2022 The Authors","Economic and social effects; Economics; Interactive computer graphics; Leisure; Virtual reality; Augmented reality technology; Avatar; Extended reality; Immersive; Metaverses; Multidisciplinary perspectives; Physical world; Second Life; Social interactions; Virtual worlds; Augmented reality",,"English",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85134587952
"Gardony A.L., Okano K., Hughes G.I., Kim A.J., Renshaw K.T., Sipolins A.","36570266900;57891197600;57891432400;57891648700;57891648800;57039175300;","Aided target recognition visual design impacts on cognition in simulated augmented reality",2022,"Frontiers in Virtual Reality","3",,"982010","","",,,"10.3389/frvir.2022.982010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138117601&doi=10.3389%2ffrvir.2022.982010&partnerID=40&md5=9d90c6bd23509dfa9279764f5bb49fc2","Aided target recognition (AiTR) systems, implemented in head-mounted and in-vehicle augmented reality (AR) displays, can enhance human performance in military operations. However, the visual appearance and delivery of AiTR may impact other important critical aspects of human performance like decision making and situational awareness (SA). Previous research suggests salient visual AR cueing, such as found in Computer-Aided Detection diagnostic systems, orient attention strongly toward cued targets leading to missed uncued targets, an effect which may be lessened by providing analog information about classification uncertainty and using less visually salient cueing techniques, such as soft highlighting. The objective of this research was to quantify the human performance impacts of two different types of AR AiTR visualizations in a simulated virtual reality defensive security task. Participants engaged in a visual camouflage discrimination task and a secondary SA Task in which participants observed and reported a peripheral human target. Critically, we manipulated the type of AiTR visualization used: 1) a traditional salient bounding box, 2) a softly glowing soft highlight, and 3) a baseline no-AiTR condition. Results revealed minimal impacts of the visual appearance of AiTR on target acquisition, target categorization, and SA but an observable reduction in user experience associated with soft highlight AiTR. Future research is needed to explore novel AiTR designs that effectively cue attention, intuitively and interpretably visualize uncertainty, and deliver acceptable user experience. Copyright © 2022 Gardony, Okano, Hughes, Kim, Renshaw and Sipolins.",,"W911QY-19-02-0003, W911QY-20-C-0078; ","English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85138117601
"Bermúdez I Badia S., Silva P.A., Branco D., Pinto A., Carvalho C., Menezes P., Almeida J., Pilacinski A.","6506360007;23475162000;57520163000;57208733566;56273736900;56592011600;37015443600;56464189400;","Virtual Reality for Safe Testing and Development in Collaborative Robotics: Challenges and Perspectives",2022,"Electronics (Switzerland)","11","11","1726","","",,7,"10.3390/electronics11111726","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130997917&doi=10.3390%2felectronics11111726&partnerID=40&md5=5b2d04914c78ae97c7c1188d55bc79d7","Collaborative robots (cobots) could help humans in tasks that are mundane, dangerous or where direct human contact carries risk. Yet, the collaboration between humans and robots is severely limited by the aspects of the safety and comfort of human operators. In this paper, we outline the use of extended reality (XR) as a way to test and develop collaboration with robots. We focus on virtual reality (VR) in simulating collaboration scenarios and the use of cobot digital twins. This is specifically useful in situations that are difficult or even impossible to safely test in real life, such as dangerous scenarios. We describe using XR simulations as a means to evaluate collaboration with robots without putting humans at harm. We show how an XR setting enables combining human behavioral data, subjective self-reports, and biosignals signifying human comfort, stress and cognitive load during collaboration. Several works demonstrate XR can be used to train human operators and provide them with augmented reality (AR) interfaces to enhance their performance with robots. We also provide a first attempt at what could become the basis for a human–robot collaboration testing framework, specifically for designing and testing factors affecting human– robot collaboration. The use of XR has the potential to change the way we design and test cobots, and train cobot operators, in a range of applications: from industry, through healthcare, to space operations. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",,"802553; PTDC/MHC-PCN/6805/2014; 2021.05646, PEest/UID/CEC/04516/2019","English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85130997917
"Zhang J., Dong Z., Bai X., Lindeman R.W., He W., Piumsomboon T.","57218772610;57218770900;57777250100;7006360047;7402007775;54885265000;","Augmented Perception Through Spatial Scale Manipulation in Virtual Reality for Enhanced Empathy in Design-Related Tasks",2022,"Frontiers in Virtual Reality","3",,"672537","","",,1,"10.3389/frvir.2022.672537","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138043170&doi=10.3389%2ffrvir.2022.672537&partnerID=40&md5=4983a750049d288838b3d13f26b12074","This research explores augmented perception by investigating the effects of spatial scale manipulation in Virtual Reality (VR) to simulate multiple levels of virtual eye height (EH) and virtual interpupillary distance (IPD) of the VR users in the design context. We have developed a multiscale VR system for design applications, which supports a dynamic scaling of the VR user’s EH and IPD to simulate different perspectives of multiple user’s groups such as children or persons with disabilities. We strongly believe that VR can improve the empathy of VR users toward the individual sharing or simulating the experience. We conducted a user study comprising two within-subjects designed experiments for design-related tasks with seventeen participants who took on a designer’s role. In the first experiment, the participants performed hazards identification and risks assessment tasks in a virtual environment (VE) while experiencing four different end-user perspectives: a two-year-old child, an eight-year-old child, an adult, and an adult in a wheelchair. We hypothesized that experiencing different perspectives would lead to different design outcomes and found significant differences in the perceived level of risks, the number of identified hazards, and the average height of hazards found. The second experiment had the participants scale six virtual chairs to a suitable scale for different target end-user groups. The participants experienced three perspectives: a two-year-old child, an eight-year-old child, and an adult. We found that when the designer’s perspective matched that of the intended end-user of the product, it yielded significantly lower variance among the designs across participants and more precise scales suitable for the end-user. We also found that the EH and IPD positively correlate with the resulting scales. The key contribution of this work is the evidence to support that spatial scale manipulation of EH and IPD could be a critical tool in the design process to improve the designer’s empathy by allowing them to experience the end-user perspectives. This could influence their design, making a safer or functionally suitable design for various end-user groups with different needs. Copyright © 2022 Zhang, Dong, Bai, Lindeman, He and Piumsomboon.",,"61850410532","English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85138043170
"Mehta R.K., Moats J., Karthikeyan R., Gabbard J.L., Srinivasan D., Du E.J., Leonessa A., Burks G., Stephenson A., Fernandes R.","55413685300;35088462500;57207449336;6603313947;55190345500;57678903500;7003758699;57193688321;57202911881;57190591240;","Human-centered intelligent training for emergency responders",2022,"AI Magazine","43","1",,"83","92",,,"10.1002/aaai.12041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134159776&doi=10.1002%2faaai.12041&partnerID=40&md5=34ae3b2f147ae02cd167cce22edd52d0","Emergency response (ER) workers perform extremely demanding physical and cognitive tasks that can result in serious injuries and loss of life. Human augmentation technologies have the potential to enhance physical and cognitive work-capacities, thereby dramatically transforming the landscape of ER work, reducing injury risk, improving ER, as well as helping attract and retain skilled ER workers. This opportunity has been significantly hindered by the lack of high-quality training for ER workers that effectively integrates innovative and intelligent augmentation solutions. Hence, new ER learning environments are needed that are adaptive, affordable, accessible, and continually available for reskilling the ER workforce as technological capabilities continue to improve. This article presents the research considerations in the design and integration of use-inspired exoskeletons and augmented reality technologies in ER processes and the identification of unique cognitive and motor learning needs of each of these technologies in context-independent and ER-relevant scenarios. We propose a human-centered artificial intelligence (AI) enabled training framework for these technologies in ER. Finally, how these human-centered training requirements for nascent technologies are integrated in an intelligent tutoring system that delivers across tiered access levels, covering the range of virtual, to mixed, to physical reality environments, is discussed. © 2022 The Authors. AI Magazine published by Wiley Periodicals LLC on behalf of the Association for the Advancement of Artificial Intelligence.","Computer aided instruction; Emergency services; Engineering education; Exoskeleton (Robotics); Personnel training; Virtual reality; Cognitive task; Cognitive work; Emergency responders; Emergency response; Injury risk; Loss of life; Physical work; Serious injuries; Work capacities; Workers'; Augmented reality",,"English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85134159776
"Afolabi A.O., Nnaji C., Okoro C.","57193827015;57189997900;57196279662;","Immersive Technology Implementation in the Construction Industry: Modeling Paths of Risk",2022,"Buildings","12","3","363","","",,2,"10.3390/buildings12030363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127521861&doi=10.3390%2fbuildings12030363&partnerID=40&md5=3bfadfb8f5e41eed7b22c4a87e7277c1","The purposes of this paper are to identify risk factors impacting the successful implementation of immersive reality technology (ImT) in the construction industry, analyze these risk factors (impact and probability), assess the relationships among different categories of risk factors, and provide recommendations to improve ImT implementation. A literature review, a pilot test based on expert interviews, and a questionnaire survey were used. First, the risk factors of ImT applications were identified by consulting the relevant literature on virtual reality, mixed reality, and augmented reality; these were subsequently grouped into five categories—technology, operation, individual/worker, investment, and external. Next, a questionnaire survey was designed and distributed to relevant construction practitioners in South Africa (usable response = 175). Twenty-one ImT implementation risk factors were identified, and risk criticality scores ranged from 2.02 to 3.18. High investment cost, the need for extensive worker training, and the possible introduction of new risks for workers were rated as significant risks. The present study confirmed three statistically significant hypothesized risk paths—namely, those between external issues and individual/worker’s concerns, between external issues and investment limitations, and between individual/worker’s concerns and technology concerns. The present study contributes to the literature regarding the adoption of construction technology by providing a list of critical risk factors that could be used to develop models and tools for assessing ImT adoption and guide practitioners involved in integrating ImTs. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",,,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85127521861
"Debauche O., Mahmoudi S., Guttadauria A.","57195530506;16177658000;57257260200;","Article A New Edge Computing Architecture for IoT and Multimedia Data Management",2022,"Information (Switzerland)","13","2","89","","",,8,"10.3390/info13020089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124799603&doi=10.3390%2finfo13020089&partnerID=40&md5=ffe63fda886d4063f5dbf564a6750790","The Internet of Things and multimedia devices generate a tremendous amount of data. The transfer of this data to the cloud is a challenging problem because of the congestion at the network level, and therefore processing time could be too long when we use a pure cloud computing strategy. On the other hand, new applications requiring the processing of large amounts of data in real time have gradually emerged, such as virtual reality and augmented reality. These new applications have gradually won over users and developed a demand for near real-time interaction of their applications, which has completely called into question the way we process and store data. To address these two problems of congestion and computing time, edge architecture has emerged with the goal of processing data as close as possible to users, and to ensure privacy protection and responsiveness in real-time. With the continuous increase in computing power, amounts of memory and data storage at the level of smartphone and connected objects, it is now possible to process data as close as possible to sensors or directly on users devices. The coupling of these two types of processing as close as possible to the data and to the user opens up new perspectives in terms of services. In this paper, we present a new distributed edge architecture aiming to process and store Internet of Things and multimedia data close to the data producer, offering fast response time (closer to real time) in order to meet the demands of modern applications. To do this, the processing at the level of the producers of data collaborate with the processing ready for the users, establishing a new paradigm of short supply circuit for data transmission inspired of short supply chains in agriculture. The removing of unnecessary intermediaries between the producer and the consumer of the data improves efficiency. We named this new paradigm the Short Supply Circuit Internet of Things (SSCIoT). © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Augmented reality; Computer architecture; Data handling; Digital storage; Information management; Internet of things; Network architecture; Supply chains; Virtual reality; A2IoT; Computing architecture; EDGE architectures; Edge computing; Image-analysis; Multimedia managements; New applications; Real- time; Short supply; Supply circuits; Edge computing",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85124799603
"Devi O.R., Webber J., Mehbodniya A., Chaitanya M., Jawarkar P.S., Soni M., Miah S.","57202735464;7101660668;55954097400;57945867500;57203061664;57202986134;57224881107;","The Future Development Direction of Cloud-Associated Edge-Computing Security in the Era of 5G as Edge Intelligence",2022,"Scientific Programming","2022",,"1473901","","",,,"10.1155/2022/1473901","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140844298&doi=10.1155%2f2022%2f1473901&partnerID=40&md5=a19e88e79dcf63a9ba45f5793a0c9520","By introducing the Internet-of-Everything, new usage situations such as self-directed movement and vivid competitions constructed upon Virtual Reality or Augmented Reality expertise, besides the Industrial-Internet-of-Thing, accelerates the initial growth of edge-registering improvements. The global versatile correspondence business is now developing toward 5G. Edge processing has gotten a lot of attention around the globe as 5G is one of the major access enhancements to advance the huge scope organization of edge registration. Edge processing security has been a significant area of concern since the advent of edge registers, limiting its execution and enhancement. Edge figuring security has been greatly hampered by the innovative structures of edge-registering, the reconciliation with a huge number of innovations, the innovative usage conditions carried on through edge-processing, and common growing requirements aimed at safety insurance. This report examines the ebb and flow of examination anxiously registering security research. This article highlights the security issues of edge processing from five perspectives, including network access, key administration, protection assurance, assault mitigation, and irregularity identification, by breaking down the safety tests among edge-registering cutting-edge terms of innovative representations, and novel applications situations, as well as innovation conditions. The study separately discusses the scholastic community's exploratory accomplishments among the applied domains, as well as the compensations for the drawbacks. In conclusion, the upcoming expansion track toward edge-computing safety has been conferred as well as projected, combining edge-cloud coordinated effort and edge intelligence. © 2022 Odugu Rama Devi et al.","5G mobile communication systems; Augmented reality; Edge computing; Virtual reality; Areas of concerns; Computing security; Condition; Development directions; Ebb-and-flow; Edge computing; Edge intelligence; Edge registration; Innovative structures; Self-directed; Internet of Everything",,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85140844298
"Mihai S., Yaqoob M., Hung D.V., Davis W., Towakel P., Raza M., Karamanoglu M., Barn B., Shetve D., Prasad R.V., Venkataraman H., Trestian R., Nguyen H.X.","57219208603;57220465729;57216845306;57216844481;57206662672;57197446345;22957756400;6506944724;57226308410;57203098734;16176653600;35868237900;57199967463;","Digital Twins: A Survey on Enabling Technologies, Challenges, Trends and Future Prospects",2022,"IEEE Communications Surveys and Tutorials","24","4",,"2255","2291",,10,"10.1109/COMST.2022.3208773","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139416099&doi=10.1109%2fCOMST.2022.3208773&partnerID=40&md5=3385e46ba470f59915fb9ed37169c7b1","Digital Twin (DT) is an emerging technology surrounded by many promises, and potentials to reshape the future of industries and society overall. A DT is a system-of-systems which goes far beyond the traditional computer-based simulations and analysis. It is a replication of all the elements, processes, dynamics, and firmware of a physical system into a digital counterpart. The two systems (physical and digital) exist side by side, sharing all the inputs and operations using real-time data communications and information transfer. With the incorporation of Internet of Things (IoT), Artificial Intelligence (AI), 3D models, next generation mobile communications (5G/6G), Augmented Reality (AR), Virtual Reality (VR), distributed computing, Transfer Learning (TL), and electronic sensors, the digital/virtual counterpart of the real-world system is able to provide seamless monitoring, analysis, evaluation and predictions. The DT offers a platform for the testing and analysing of complex systems, which would be impossible in traditional simulations and modular evaluations. However, the development of this technology faces many challenges including the complexities in effective communication and data accumulation, data unavailability to train Machine Learning (ML) models, lack of processing power to support high fidelity twins, the high need for interdisciplinary collaboration, and the absence of standardized development methodologies and validation measures. Being in the early stages of development, DTs lack sufficient documentation. In this context, this survey paper aims to cover the important aspects in realization of the technology. The key enabling technologies, challenges and prospects of DTs are highlighted. The paper provides a deep insight into the technology, lists design goals and objectives, highlights design challenges and limitations across industries, discusses research and commercial developments, provides its applications and use cases, offers case studies in industry, infrastructure and healthcare, lists main service providers and stakeholders, and covers developments to date, as well as viable research dimensions for future developments in DTs. © 1998-2012 IEEE.","Artificial intelligence; Augmented reality; Distributed computer systems; Firmware; Industrial research; Industry 4.0; Internet of things; Network security; Real time systems; Surveys; Systems engineering; Virtual reality; 5g; Digital transformation; Emerging technologies; Enabling technologies; Future prospects; Market researches; Smart manufacturing; Solid modelling; Technology challenges; Tutorial; Data visualization","2022-2024, 429715093; DST UKIERI-2018-19-011; DA00192, VINIF.2021","English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85139416099
"Peng Y., Xue X., Bashir A.K., Zhu X., Al-Otaibi Y.D., Tariq U., Yu K.","36667155900;57455322300;57193954653;57204546994;57213689300;14827558600;56316023300;","Securing Radio Resources Allocation With Deep Reinforcement Learning for IoE Services in Next-Generation Wireless Networks",2022,"IEEE Transactions on Network Science and Engineering","9","5",,"2991","3003",,,"10.1109/TNSE.2022.3149750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124735113&doi=10.1109%2fTNSE.2022.3149750&partnerID=40&md5=9f742fcc5b9223dae47328d5fe4346c4","The next generation wireless network (NGWN) is undergoing an unprecedented revolution, in which trillions of machines, people, and objects are interconnected to realize the Internet of Everything (IoE). with the emergence of IoE services such as virtual reality, augmented reality, and industrial 5 G, the scarcity of radio resources becomes more serious. Moreover, there are hidden dangers of untrusted terminals accessing the system and illegally manipulating interconnected devices. To tackle these challenges, this paper proposes a securing radio resources allocation scheme with Deep Reinforcement Learning for IoE services in NGWN. First, the solution uses a BP neural network based on multi-feature optimized Firefly Algorithm (FA) for spectrum prediction, thereby improving the prediction accuracy and avoiding interference between unauthorized and authorized users with efficient radio utilization. Then, a spectrum sensing method based on deep reinforcement learning is proposed to identify the untrusted users in system while fusing the sensing results, to enhance the security of the cooperative process and the detection accuracy of spectrum holes. Extensive simulation results show that the proposal is superior to the traditional solutions in terms of prediction accuracy, spectrum utilization and energy consumption, and is suitable for deployment in future wireless systems. © 2013 IEEE.","5G mobile communication systems; Augmented reality; Deep neural networks; Energy utilization; Forecasting; Heuristic algorithms; Internet of Everything; Learning algorithms; Next generation networks; Optimization; Radio; Radio access networks; Resource allocation; Spectrum efficiency; Virtual reality; Wireless networks; Deep reinforcement learning; Energy-consumption; Firefly algorithms; Next generation networking; Next-generation wireless network; Prediction algorithms; Radio resource allocation; Reinforcement learnings; Resource management; Wireless communications; Reinforcement learning",,"English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85124735113
"Kim J., Knox D., Park H.","52863809900;57245299300;55516766800;","Forehead tactile hallucination is augmented by the perceived risk and accompanies increase of forehead tactile sensitivity",2021,"Sensors","21","24","8246","","",,,"10.3390/s21248246","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120818389&doi=10.3390%2fs21248246&partnerID=40&md5=77a3aa7620a94e793f0d7296a5eff30e","Tactile hallucinations frequently occur after mental illnesses and neurodegenerative dis-eases like Alzheimer’s and Parkinson’s disease. Despite their common occurrence, there are several complicating factors that make it difficult to elucidate the tactile hallucinations. The forehead tactile hallucination, evoked by the physical object approaching to the forehead, can be easily and consistently evoked in healthy-bodied subjects, and therefore it would help with investigating the mechanism of tactile hallucinations. In this pilot study, we investigated the principles of the forehead tactile hallucination with eight healthy subjects. We designed the experimental setup to test the effect of sharpness and speed of objects approaching towards the forehead on the forehead tactile hallucination, in both a physical and virtual experimental setting. The forehead tactile hallucination was successfully evoked by virtual object as well as physical object, approaching the forehead. The forehead tactile hallucination was increased by the increase of sharpness and speed of the approaching object. The forehead tactile hallucination also increased the tactile sensitivity on the forehead. The forehead tactile hallucination can be solely evoked by visual feedback and augmented by the increased perceived risk. The forehead tactile hallucination also increases tactile sensitivity. These experimental results may enhance the understanding of the foundational mechanisms of tactile hallucinations. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Neurodegenerative diseases; Virtual reality; Alzheimer; Forehead sensation; Mental illness; Neurodegenerative; Perceived risk; Physical objects; Pilot studies; Tactile hallucination; Tactile sensitivities; Visual communication; forehead; hallucination; human; mental disease; Parkinson disease; pilot study; Forehead; Hallucinations; Humans; Mental Disorders; Parkinson Disease; Pilot Projects",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85120818389
"Hassantabar S., Stefano N., Ghanakota V., Ferrari A., Nicola G.N., Bruno R., Marino I.R., Hamidouche K., Jha N.K.","57218368245;57219761518;57219759855;57471500900;55519882600;7101907548;7006140736;56297968300;7102310305;","CovidDeep: SARS-CoV-2/COVID-19 Test Based on Wearable Medical Sensors and Efficient Neural Networks",2021,"IEEE Transactions on Consumer Electronics","67","4",,"244","256",,12,"10.1109/TCE.2021.3130228","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120036670&doi=10.1109%2fTCE.2021.3130228&partnerID=40&md5=36e5d0e3c3989a1105c21fdda434cf89","The novel coronavirus (SARS-CoV-2) has led to a pandemic. The current testing regime based on Reverse Transcription-Polymerase Chain Reaction for SARS-CoV-2 has been unable to keep up with testing demands, and also suffers from a relatively low positive detection rate in the early stages of the resultant COVID-19 disease. Hence, there is a need for an alternative approach for repeated large-scale testing of SARS-CoV-2/COVID-19. The emergence of wearable medical sensors (WMSs) and deep neural networks (DNNs) points to a promising approach to address this challenge. WMSs enable continuous and user-transparent monitoring of physiological signals. However, disease detection based on WMSs/DNNs and their deployment on resource-constrained edge devices remain challenging problems. To address these problems, we propose a framework called CovidDeep that combines efficient DNNs with commercially available WMSs for pervasive testing of the virus and the resultant disease. CovidDeep does not depend on manual feature extraction. It directly operates on WMS data and some easy-to-answer questions in a questionnaire whose answers can be obtained through a smartphone application. We collected data from 87 individuals, spanning three cohorts including healthy, asymptomatic (to detect the virus), and symptomatic (to detect the disease) patients. We trained DNNs on various subsets of the features automatically extracted from six WMS and questionnaire categories to perform ablation studies to determine which subsets are most efficacious in terms of test accuracy for a three-way classification. The highest test accuracy obtained was 98.1%. The models were also shown to perform well on other performance measures, such as false positive rate, false negative rate, and F1 score. We augmented the real training dataset with a synthetic training dataset drawn from the same probability distribution to impose a prior on DNN weights and leveraged a grow-and-prune synthesis paradigm to learn both DNN architecture and weights. This boosted the accuracy of the various DNNs further and simultaneously reduced their size and floating-point operations. This makes the CovidDeep DNNs both accurate and efficient, in terms of memory requirements and computations. The resultant DNNs are embedded in a smartphone application, which has the added benefit of preserving patient privacy. © 1975-2011 IEEE.","Computer architecture; Deep neural networks; Diagnosis; Digital arithmetic; Hybrid systems; mHealth; Network architecture; Online systems; Personnel training; Polymerase chain reaction; Probability distributions; Surveys; Virtual reality; Wearable sensors; Biomedical monitoring; Brain modeling; Coronaviruses; COVID-19; COVID-19 test; Deep neural network; Grow-and-prune synthesis; Internet of medical thing; Medical services; Online computing; SARS-CoV-2; Smart healthcare; Synthetic data generations; Wearable online computing; Wearable system.; Wearable systems; SARS","CNS-1907381","English",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85120036670
"Loureiro S.M.C., Nascimento J.","27467492100;57340196900;","Shaping a view on the influence of technologies on sustainable tourism",2021,"Sustainability (Switzerland)","13","22","2691","","",,11,"10.3390/su132212691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119200002&doi=10.3390%2fsu132212691&partnerID=40&md5=e4ac5d80ecdd1d424f45eb5b86784973","To date, tourism is the fastest growing industry globally, but one of the least developed in terms of environmentally sustainable practices. However, only a small portion of documents elaborate on how the introduction of new technologies can impact a more sustainable development route for tourism. This study’s objective is to provide an overview on literature state‐of‐the‐art related to sustainable tourism and technological innovations, offering insights for further advancing this domain. We employ a bibliometric analysis and a comprehensive review of 139 articles, collected from Web of Science and Scopus databases, for the purpose of: (i) exploring and discussing the most relevant contributions in the publication network: (ii) highlighting key issues and emerging topics; (iii) uncovering open questions for the future. Our findings reveal contradictory views on the risks and benefits of technology adoption. Artificial intelligence, internet of things, circular economy, big data, augmented and virtual reality emerge as major trends. Five work streams are identified and described, leading to a broader perspective on how technology can shape the future of sustainable tourism. Relevant theoretical and managerial implications are derived. Finally, a research agenda is proposed as guidance for future studies addressing the outcomes of digital disruption on sustainable tourism. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","ecotourism; innovation; sustainable development; technology adoption; virtual reality; Scopus",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85119200002
"Georgieva D., Koleva G., Hristova I.","57199852321;57199862387;57205662717;","Virtual Technologies in the Medical Professions - Creation of 360 - Degree Environments for Health Care Training",2021,"TEM Journal","10","3",,"1314","1318",,2,"10.18421/TEM103-39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116488248&doi=10.18421%2fTEM103-39&partnerID=40&md5=86a34dc7e75b76cb0e359c80272d96b9","This article presents a study of the advantages of virtual technologies in health education, as well as an attempt to answer the following questions. How XR could improve the educational process by boosting the current ratio of students to lecturers while maintaining the same level of efficacy. How XR technologies could provide access to critical knowledge around the clock without interfering with the workflow of healthcare facilities and without exposing patients to any undue risk. The practical application of a 360° virtual world for a clinical laboratory, central laboratory for sterilization and a virtual operating room all in partnership between the Healthcare Department of Angel Kanchev University of Ruse, The Yatrus Foundation IT Specialists and University Multidisciplinary Hospital for Active Treatment Kanev, Ruse. The virtual reality allows the trainees to explore, to make mistakes and learn from them before ultimately applying the real procedure on a patient. © 2021. Despina Georgieva, Greta Koleva & Irinka Hristova; published by UIKTEN. This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 License.",,,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85116488248
"Higgins D., Fribourg R., McDonnell R.","57223645403;57203970110;24537203400;","Remotely Perceived: Investigating the Influence of Valence on Self-Perception and Social Experience for Dyadic Video-Conferencing With Personalized Avatars",2021,"Frontiers in Virtual Reality","2",,"668499","","",,4,"10.3389/frvir.2021.668499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129441594&doi=10.3389%2ffrvir.2021.668499&partnerID=40&md5=6fba0587d7412bddeb73f86d5788853a","Avatar use on video-conference platforms has found dual purpose in recent times as a potential method for ensuring privacy and improving subjective engagement with remote meeting, provided one can also ensure a minimal loss in the quality of social interaction and sense of personal presence. This work focuses on interactions of this sort through real-time motion captured 3D personalized virtual avatars in a 2D video-conferencing context. Our experiments were designed with the intention of exploring previously defined perceptual illusions that occur with avatar-use in Virtual and Augmented Reality settings, outside of the immersive technological domains where they are normally measured. The research described here was aimed at empirically evaluating three separate dimensions of human-avatar interaction. The first was humans-as-avatars, with experimental conditions that were designed to measure changes to subjective perceptions of self-face ownership and self-concept. The second focus was other-perception, with the unique design of the studies outlined below among the first to measure social presence in a video-call between two human-driven avatars. The third emphasis was on the experiential content involved in avatar use, as there were measurements for emotion induction, fatigue and behavior change included in the data collection. The results describe some evidence for face and body ownership, while participants also reported high levels of social presence with the other avatar, indicating that avatar cameras could be a favorable alternative to non-camera feeds in video conferencing. There were also some useful insights gained regarding emotion elicitation in non-video vs. avatar conditions, as well as avatar-induced behavior change. Copyright © 2021 Higgins, Fribourg and McDonnell.",,"18/CRT/6224; 19/FFP/6409","English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85129441594
"Longo U.G., De Salvatore S., Candela V., Zollo G., Calabrese G., Fioravanti S., Giannone L., Marchetti A., De Marinis M.G., Denaro V.","55308310300;56191104200;57192230877;57222957229;57222960233;57225723440;57222013055;56651842000;22834503100;7004909863;","Augmented reality, virtual reality and artificial intelligence in orthopedic surgery: A systematic review",2021,"Applied Sciences (Switzerland)","11","7","3253","","",,10,"10.3390/app11073253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104266439&doi=10.3390%2fapp11073253&partnerID=40&md5=f1cabddcf295f09f533134e918623293","Background: The application of virtual and augmented reality technologies to orthopaedic surgery training and practice aims to increase the safety and accuracy of procedures and reducing complications and costs. The purpose of this systematic review is to summarise the present literature on this topic while providing a detailed analysis of current flaws and benefits. Methods: A comprehensive search on the PubMed, Cochrane, CINAHL, and Embase database was conducted from inception to February 2021. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines were used to improve the reporting of the review. The Cochrane Risk of Bias Tool and the Methodological Index for Non-Randomized Studies (MINORS) was used to assess the quality and potential bias of the included randomized and non-randomized control trials, respectively. Results: Virtual reality has been proven revolutionary for both resident training and preoperative planning. Thanks to augmented reality, orthopaedic surgeons could carry out procedures faster and more accurately, improving overall safety. Artificial intelligence (AI) is a promising technology with limitless potential, but, nowadays, its use in orthopaedic surgery is limited to preoperative diagnosis. Conclusions: Extended reality technologies have the potential to reform orthopaedic training and practice, providing an opportunity for unidirectional growth towards a patient-centred approach. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",,,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85104266439
"González C., Solanes J.E., Muñoz A., Gracia L., Girbés-Juan V., Tornero J.","57224678108;50362016600;57197194186;57198068796;57217682767;56162306600;","Advanced teleoperation and control system for industrial robots based on augmented virtuality and haptic feedback",2021,"Journal of Manufacturing Systems","59",,,"283","298",,26,"10.1016/j.jmsy.2021.02.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102363990&doi=10.1016%2fj.jmsy.2021.02.013&partnerID=40&md5=0ec376859c4a346c56cc656ebcc60cf9","There are some industrial tasks that are still mainly performed manually by human workers due to their complexity, which is the case of surface treatment operations (such as sanding, deburring, finishing, grinding, polishing, etc.) used to repair defects. This work develops an advanced teleoperation and control system for industrial robots in order to assist the human operator to perform the mentioned tasks. On the one hand, the controlled robotic system provides strength and accuracy, holding the tool, keeping the right tool orientation and guaranteeing a smooth approach to the workpiece. On the other hand, the advanced teleoperation provides security and comfort to the user when performing the task. In particular, the proposed teleoperation uses augmented virtuality (i.e., a virtual world that includes non-modeled real-world data) and haptic feedback to provide the user an immersive virtual experience when remotely teleoperating the tool of the robot system to treat arbitrary regions of the workpiece surface. The method is illustrated with a car body surface treatment operation, although it can be easily extended to other surface treatment applications or even to other industrial tasks where the human operator may benefit from robotic assistance. The effectiveness of the proposed approach is shown with several experiments using a 6R robotic arm. Moreover, a comparison of the performance obtained manually by an expert and that obtained with the proposed method has also been conducted in order to show the suitability of the proposed approach. © 2021 The Society of Manufacturing Engineers","Deburring; End effectors; Feedback; Man machine systems; Personnel; Remote control; Robotics; Social robots; Surface treatment; User experience; Virtual reality; Augmented virtualities; Haptic feedbacks; Human operator; Industrial tasks; Robot system; Robotic systems; Tool orientation; Virtual worlds; Industrial robots","GV/2021/005, PID2020-117421RB-C21","English",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85102363990
"Bajic B., Rikalovic A., Suzic N., Piuri V.","57220915976;55440580900;55554334700;35426171300;","Industry 4.0 Implementation Challenges and Opportunities: A Managerial Perspective",2021,"IEEE Systems Journal","15","1","9207825","546","559",,55,"10.1109/JSYST.2020.3023041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102753016&doi=10.1109%2fJSYST.2020.3023041&partnerID=40&md5=debc3590c829d5686569ec9e71630247","Industry 4.0 is a concept aimed at achieving the integration of physical parts of the manufacturing process (i.e., complex machinery, various devices, and sensors) and cyber parts (i.e., advanced software) via networks and driven by Industry 4.0 technology categories used for prediction, control, maintenance, and integration of manufacturing processes. Industry 4.0, which is expected to have a great impact on manufacturing systems in the future, is attracting attention in both industry and academia. Although academic research on Industry 4.0 is growing exponentially, evidence of Industry 4.0 implementation in practice is still scarce. Moreover, the challenges industry faces when implementing the Industry 4.0 concept seem to be even less addressed. At the start of the present survey, a preliminary literature review identified a lack of comprehensive analysis of the Industry 4.0 implementation challenges. Thus, the purpose of the present article is to provide an overview of the reported Industry 4.0 implementation challenges in the relevant literature by conducting a systematic literature review. Specifically, while the present study differentiates between managerial and technological Industry 4.0 implementation challenges, the focus of the present article is on the managerial Industry 4.0 implementation challenges. This overview is performed by deriving an inductively coded Industry 4.0 technology framework that classifies Industry 4.0 technologies into ten categories: cyber physical systems, Internet of Things, big data analytics, cloud computing, fog and edge computing, augmented and virtual reality, robotics, cyber security, semantic web technologies, and additive manufacturing. The present article identifies, codes, and defines the managerial Industry 4.0 implementation challenges and derives opportunities for overcoming them. © 2007-2012 IEEE.","3D printers; Advanced Analytics; Data Analytics; Embedded systems; Industry 4.0; Machinery; Managers; Security of data; Advanced softwares; Augmented and virtual realities; Complex machinery; Comprehensive analysis; Literature reviews; Manufacturing process; Semantic Web technology; Systematic literature review; Industrial robots","825333; ","English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85102753016
"Bhattacharya P., Saraswat D., Dave A., Acharya M., Tanwar S., Sharma G., Davidson I.E.","57200306370;57224616778;57393056700;57392754300;56576145100;57216326306;7103403083;","Coalition of 6G and Blockchain in AR/VR Space: Challenges and Future Directions",2021,"IEEE Access","9",,,"168455","168484",,11,"10.1109/ACCESS.2021.3136860","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122105296&doi=10.1109%2fACCESS.2021.3136860&partnerID=40&md5=05fe2c3cf64bde17fcf9d0129839edbb","The digital content wave has proliferated the financial and industrial sectors. Moreover, with the rise of massive internet-of-things, and automation, technologies like augmented reality (AR) and virtual reality (VR) have emerged as prominent players to drive a range of applications. Currently, sixth-generation (6G) networks support enhanced holographic projection through terahertz (THz) bandwidths, ultra-low latency, and massive device connectivity. However, the data is exchanged between autonomous networks over untrusted channels. Thus, to ensure data security, privacy, and trust among stakeholders, blockchain (BC) opens new dimensions towards intelligent resource management, user access control, audibility, and chronology in stored transactions. Thus, the BC and 6G coalition in future AR/VR applications is an emerging investigative topic. To date, authors have proposed surveys that study the integration of BC and 6G in AR/VR in isolation, and hence a coherent survey is required. Thus, to address the gap, the survey is the first-of-its-kind to investigate and study the coalition of BC and 6G in AR/VR space. Based on the proposed research questions in the survey, a solution taxonomy is presented, and different verticals are studied in detail. Furthermore, an integrative architecture is proposed, and open issues and challenges are presented. Finally, a case study, BvTours, is presented that presents a unique survey on BC-based 6G-assisted AR/VR virtual home tour service. The survey intends to propose future resilient frameworks and architectures for different industry 4.0 verticals and would serve as starting directions for academia, industry stakeholders, and research organizations to study the coalition of BC and 6G in AR/VR in industrial applications, gaming, digital content manufacturing, and digital assets protection in greater detail. © 2013 IEEE.","5G mobile communication systems; Access control; Augmented reality; Digital storage; Industrial research; Industry 4.0; Information management; Interactive computer systems; Network architecture; Quality of service; Real time systems; Surveys; Virtual reality; 6g; 6g mobile communication; Block-chain; Digital contents; Financial sectors; Medical services; Mobile communications; Real - Time system; Virtual reality application; Smart contract",,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85122105296
"Rinaldi C., Franchi F., Marotta A., Graziosi F., Centofanti C.","56649934400;57193013263;57191035019;7004365263;57210853439;","On the Exploitation of 5G Multi-Access Edge Computing for Spatial Audio in Cultural Heritage Applications",2021,"IEEE Access","9",,,"155197","155206",,4,"10.1109/ACCESS.2021.3128786","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120524056&doi=10.1109%2fACCESS.2021.3128786&partnerID=40&md5=c2b2d6a7040009c5f2d49471a55bf659","This work presents a service for the improvement of cultural heritage experiences, which exploits the advantages coming from the 5G paradigm. Indeed, in a scenario where many users need to be served by a real-time solution which is in turn required to work on different devices, the potentialities of 5G technology show their suitability. In particular, moving the computation to the edge of the network ensures the availability of resources needed for binaural spatial audio rendering in an independent fashion with reference to the client device and at the same time it guarantees real-time availability of this data since the core network, with its impairments, is not involved. This work demonstrates how 5G could be a critical enabler for delivering low latency services at guaranteed levels, data-centric services, differentiated customer experiences, improved security and reduced costs to the users. © 2013 IEEE.","5G mobile communication systems; Augmented reality; Edge computing; Binaural rendering; Cloud-computing; Cultural heritage application; Cultural heritages; Edge computing; Multi-access edge computing; Multiaccess; Real time solution; Spatial audio; User need; Virtual reality","872866","English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85120524056
"Veiga F.J.M., de Andrade A.M.V.","57218387061;57224643653;","Critical Success Factors in Accepting Technology in the Classroom",2021,"International Journal of Emerging Technologies in Learning","16","18",,"4","22",,7,"10.3991/ijet.v16i18.23159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115621315&doi=10.3991%2fijet.v16i18.23159&partnerID=40&md5=013a7280119e590a2c420fb6c86c55df","The adoption of technology on the individual and organizational level may be a necessary condition, but it is not sufficient for the digital transformation, seen as the mobilizing challenge to do something new and different. Without a strategic vision, we take the risk of acquiring resources to do the same as before, essentially changing the format. This inability imprisons the school to inconsequential models, resources and strategies. Interdisciplinary, social and project-based learning that the most advanced technology provides can be adopted. Augmented and virtual reality, the internet of things, robots, artificial intelligence and digital assistants can bring innovation to teaching. But also mobiles, games, simulators and multimedia can inspire collaborative creativity. On the other hand, the pandemic, in terms of the adoption of technology, constitutes a kind of insurrection against the fatalism that it is not possible to restart the system, that is, rethink the school. This study aims at investigating the degree of acceptance, materialized in the use of technology, by teachers of primary and secondary education, in the context of the classroom. As a methodological support to this study, the model “Unified Theory of Acceptance and Use of Technology” (UTAUT)) was used and a questionnaire applied to teachers at our school, obtaining 90 responses. The analysis of the responses reveals that the expected adoption of information technologies currently has a global performance, which becomes the most significant positive influence on the motivation and involvement of teachers. That is, the availability of technology, the speed of access, the applications suited to the curriculum and to the pedagogical approach are, more and more, a harmonious set that is compatible with its mission. The study also clarifies that teachers intend to use ICT as they see in them a different didactic tool that allows different approaches, thus increasing, in general, the quality of teaching and learning. © 2021. All Rights Reserved.","Engineering education; Intelligent robots; Teaching; Virtual reality; Individual levels; Success factors; Teacher behavior; Teachers'; Technology; Technology acceptance; Technology acceptance and use (unified theory of acceptance and use of technology”); Technology in the classroom; Technology use; The unified theory of acceptance and use of technology(UTAUT); Curricula",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85115621315
"Zhuang Y.","57218292294;","Optimization of the Personalized Service System of University Library Based on Internet of Things Technology",2021,"Wireless Communications and Mobile Computing","2021",,"5589505","","",,5,"10.1155/2021/5589505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107162164&doi=10.1155%2f2021%2f5589505&partnerID=40&md5=9e7ccedff1f1f59c55af5e8bc3f0aa3a","In library applications, radio frequency indentification (RFID) technology, sensors, and wireless transmission networks have been applied to various services such as self-service checkout and return systems, electronic reader cards, intelligent bookshelves, intelligent monitoring of library premises, augmented reality (AR) interactive picture books, physical corridors, and seat reservations; in regional library alliances, real crossregional and cross-system alliance cooperation through IoT technology is also becoming increasingly important. Continuous information resource sharing is an important means to maximize the effectiveness of library information resources and meet the information needs of various users. The development of IoT technology opens new ideas and methods for information resource sharing in regional library alliances, effectively expanding the scope of information resource sharing and improving the efficiency of information resource sharing. This paper briefly presents the relationship, architecture, and key technologies of IoT technology and the definition, characteristics, and types of regional library consortium and content. Analysis of the characteristics and principles of regional library consortium information resource sharing is in the context of IoT and the corresponding studies on information sharing between regional library consortia at home and abroad. We also propose strategies to establish a specialized agency for information resource sharing, establish a sound investment mechanism for information resource sharing, ensure the security of information resource sharing of the regional library consortium, and increase the publicity and training capacity of information resource sharing of the regional library consortium. © 2021 Yi Zhuang.","Augmented reality; Digital libraries; Internet of things; Radio transmission; Security of data; Technology transfer; Information resource; Information sharing; Intelligent monitoring; Internet of things technologies; Personalized service; Regional library alliances; University libraries; Wireless transmissions; Information dissemination",,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85107162164
"Wang Y., Zhang D., Wei S.","57223840806;57223831588;57223793995;","Effect of Nursing Intervention in the Operating Room Based on Simple Virtual Reality Augmented Technology on Preventing Gastrointestinal Surgical Incision Infection",2021,"Journal of Healthcare Engineering","2021",,"9981821","","",,3,"10.1155/2021/9981821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106153316&doi=10.1155%2f2021%2f9981821&partnerID=40&md5=93ceef1fe0364050cb393d5df8db8f85","Gastrointestinal surgery is currently a common gastrointestinal surgery in clinical practice. In recent years, the incidence of gastrointestinal diseases has gradually increased and increased as the lifestyle of modern people has developed and changed. Both physical health and quality of life have a serious impact. In the actual process, it was found that multiple links in operating room care may increase the risk of postoperative infections for patients. Therefore, this article proposes nursing in operating room based on simple virtual reality augmented technology. This article mainly studies the effect of nursing intervention on preventing gastrointestinal surgical incision infection, and hopes to provide help for preventing gastrointestinal surgical incision infection. In this trial, 80 patients with gastrointestinal surgery were randomly divided into two groups, each with 40 people. The experimental group was treated with an operating room nursing intervention combined with traditional treatment methods. Controls were treated with traditional nursing combined with traditional treatment, and both groups were analyzed for acceptance of nursing intervention in the operating room, poor mood, various indicator levels, postoperative complications, and postoperative incisional infections. The experiment proved that the postoperative rehabilitation indexes of the experimental group were better than those of the control group, the excellent rate of wound healing reached 92.5%, and the incidence of wound infection was only 5%, which was lower than that of the control group. This demonstrates that nursing intervention in the operating room can help to reduce the infection rate at the patient's incision site, increase the level of surgical indicators, promote healing of the incision site as quickly as possible, and significantly improve the safety of clinical treatment. © 2021 Yanhua Wang et al.","Nursing; Operating rooms; Surgery; Tissue regeneration; Clinical practices; Clinical treatments; Experimental groups; Gastrointestinal Disease; Nursing interventions; Postoperative complications; Postoperative rehabilitations; Treatment methods; Virtual reality; adult; anxiety; Article; augmented reality; bloating; controlled study; depression; diarrhea; fear; female; gastrointestinal surgery; human; hyperglycemia; hypoglycemia; incidence; incision; infection prevention; major clinical study; male; middle aged; nursing intervention; patient worry; postoperative care; postoperative vomiting; quality of life; randomized controlled trial; rehabilitation care; surgical infection; tension; virtual reality; wound healing; complication; operating room; surgical infection; surgical wound; technology; Humans; Operating Rooms; Quality of Life; Surgical Wound; Surgical Wound Infection; Technology; Virtual Reality",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85106153316
"Li Y., Cheng Y., Meng W., Li Y., Deng R.H.","57192521667;55734767200;56062319900;8365610600;57203710994;","Designing Leakage-Resilient Password Entry on Head-Mounted Smart Wearable Glass Devices",2021,"IEEE Transactions on Information Forensics and Security","16",,"9153060","307","321",,13,"10.1109/TIFS.2020.3013212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089295750&doi=10.1109%2fTIFS.2020.3013212&partnerID=40&md5=a58f58703247eab31d959a8df9ea7588","With the boom of Augmented Reality (AR) and Virtual Reality (VR) applications, head-mounted smart wearable glass devices are becoming popular to help users access various services like E-mail freely. However, most existing password entry schemes on smart glasses rely on additional computers or mobile devices connected to smart glasses, which require users to switch between different systems and devices. This may greatly lower the practicability and usability of smart glasses. In this paper, we focus on this challenge and design three practical anti-eavesdropping password entry schemes on stand-alone smart glasses, named gTapper, gRotator and gTalker. The main idea is to break the correlation between the underlying password and the interaction observable to adversaries. In our IRB-approved user study, these schemes are found to be easy-to-use without additional hardware under various test conditions, where the participants can enter their passwords within moderate time, at high accuracy, and in various situations. © 2005-2012 IEEE.","Augmented reality; Authentication; Virtual reality; Wearable computers; Glass devices; High-accuracy; Smart glass; Smart wearables; Stand -alone; Test condition; User study; Users access; Glass","61802289, 830929; ","English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85089295750
"McGill M., Williamson J., Ng A., Pollick F., Brewster S.","35213728600;39062233100;55841483000;7004147308;7006514160;","Challenges in passenger use of mixed reality headsets in cars and other transportation",2020,"Virtual Reality","24","4",,"583","603",,20,"10.1007/s10055-019-00420-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077029674&doi=10.1007%2fs10055-019-00420-x&partnerID=40&md5=82c5b92033412cb48470565bd652a652","This paper examines key challenges in supporting passenger use of augmented and virtual reality headsets in transit. These headsets will allow passengers to break free from the restraints of physical displays placed in constrained environments such as cars, trains and planes. Moreover, they have the potential to allow passengers to make better use of their time by making travel more productive and enjoyable, supporting both privacy and immersion. However, there are significant barriers to headset usage by passengers in transit contexts. These barriers range from impediments that would entirely prevent safe usage and function (e.g. motion sickness) to those that might impair their adoption (e.g. social acceptability). We identify the key challenges that need to be overcome and discuss the necessary resolutions and research required to facilitate adoption and realize the potential advantages of using mixed reality headsets in transit. © 2019, The Author(s).","Augmented reality; Transportation; Virtual reality; Augmented and virtual realities; Motion sickness; Passenger; Social acceptability; Travel; Mixed reality","835197; 303740; 77563/1; ","English",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85077029674
"Liu Y., Liu Y., Xu S., Cheng K., Masuko S., Tanaka J.","57218311654;57218311577;57210152285;57195592672;55876715000;35103690300;","Comparing vr-and ar-based try-on systems using personalized avatars",2020,"Electronics (Switzerland)","9","11","1814","1","25",,10,"10.3390/electronics9111814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094929317&doi=10.3390%2felectronics9111814&partnerID=40&md5=fecc6d5fdd758d520564e3f052a03a79","Despite the convenience offered by e-commerce, online apparel shopping presents various product-related risks, as consumers can neither physically see nor try products on themselves. Augmented reality (AR) and virtual reality (VR) technologies have been used to improve the shopping online experience. Therefore, we propose an AR-and VR-based try-on system that provides users a novel shopping experience where they can view garments fitted onto their personalized virtual body. Recorded personalized motions are used to allow users to dynamically interact with their dressed virtual body in AR. We conducted two user studies to compare the different roles of VR-and AR-based try-ons and validate the impact of personalized motions on the virtual try-on experience. In the first user study, the mobile application with the AR-and VR-based try-on is compared to a traditional e-commerce interface. In the second user study, personalized avatars with pre-defined motion and personalized motion is compared to a personalized no-motion avatar with AR-based try-on. The result shows that AR-and VR-based try-ons can positively influence the shopping experience, compared with the traditional e-commerce interface. Overall, AR-based try-on provides a better and more realistic garment visualization than VR-based try-on. In addition, we found that personalized motions do not directly affect the user’s shopping experience. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",,,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85094929317
"Malik A., Hiekkanen K., Hussain Z., Hamari J., Johri A.","56452232200;37017103300;23567987300;35361989600;25655003800;","How players across gender and age experience Pokémon Go?",2020,"Universal Access in the Information Society","19","4",,"799","812",,7,"10.1007/s10209-019-00694-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074590042&doi=10.1007%2fs10209-019-00694-7&partnerID=40&md5=a2fff4901b5127fb1bba0e4160bf59e6","The purpose of this study is to provide insights into player experiences and motivations in Pokémon Go, a relatively new phenomenon of location-based augmented reality games. With the increasing usage and adoption of various forms of digital games worldwide, investigating the motivations for playing games has become crucial not only for researchers but for game developers, designers, and policy makers. Using an online survey (N = 1190), the study explores the motivational, usage, and privacy concerns variations among age and gender groups of Pokémon Go players. Most of the players, who are likely to be casual gamers, are persuaded toward the game due to nostalgic association and word of mouth. Females play Pokémon Go to fulfill physical exploration and enjoyment gratifications. On the other hand, males seek to accomplish social interactivity, achievement, coolness, and nostalgia gratifications. Compared to females, males are more concerned about the privacy aspects associated with the game. With regard to age, younger players display strong connotation with most of the studied gratifications and the intensity drops significantly with an increase in age. With the increasing use of online and mobile games worldwide among all cohorts of society, the study sets the way for a deeper analysis of motivation factors with respect to age and gender. Understanding motivations for play can provide researchers with the analytic tools to gain insight into the preferences for and effects of game play for different kinds of users. © 2019, The Author(s).","Augmented reality; Software design; Virtual reality; Free to plays; Freemium; Location based games; On-line games; Uses and gratifications; Motivation","40009/16, 5654/31/2018; 142444; 1424444, 1707837; ","English",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85074590042
"Zhani M.F., ElBakoury H.","24484310400;55359434900;","FlexNGIA: A Flexible Internet Architecture for the Next-Generation Tactile Internet",2020,"Journal of Network and Systems Management","28","4",,"751","795",,19,"10.1007/s10922-020-09525-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082826900&doi=10.1007%2fs10922-020-09525-0&partnerID=40&md5=bc1695798fd82df1fff266fcc0f4a1aa","From virtual reality and telepresence, to augmented reality, holoportation, and remotely controlled robotics, these future network applications promise an unprecedented development for society, economics and culture by revolutionizing the way we live, learn, work and play. In order to deploy such futuristic applications and to cater to their performance requirements, recent trends stressed the need for the “Tactile Internet”, an Internet that, according to the International Telecommunication Union (ITU), combines ultra low latency with extremely high availability, reliability and security (ITU-T Technology Watch Report. The Tactile Internet, 2014). Unfortunately, today’s Internet falls short when it comes to providing such stringent requirements due to several fundamental limitations in the design of the current network architecture and communication protocols. This brings the need to rethink the network architecture and protocols, and efficiently harness recent technological advances in terms of virtualization and network softwarization to design the Tactile Internet of the future. In this paper, we start by analyzing the characteristics and requirements of future networking applications. We then highlight the limitations of the traditional network architecture and protocols and their inability to cater to these requirements. Afterward, we put forward a novel network architecture adapted to the Tactile Internet called FlexNGIA, a Flexible Next-Generation Internet Architecture. We then describe some use-cases where we discuss the potential mechanisms and control loops that could be offered by FlexNGIA in order to ensure the required performance and reliability guarantees for future applications. Finally, we identify the key research challenges to further develop FlexNGIA towards a full-fledged architecture for the future Tactile Internet. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Augmented reality; Network function virtualization; Next generation networks; Software defined networking; Virtual reality; Visual communication; High-precision; In networks; Low latency; Next generation Internet; Transport protocols; Internet protocols",,"English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85082826900
"Wunder L., Gomez N.A.G., Gonzalez J.E., Mitzova-Vladinov G., Cacchione M., Mato J., Foronda C.L., Groom J.A.","56438024700;57217082597;57108558900;56560155100;36622831000;57219709222;24381480800;12142837200;","Fire in the operating room: Use of mixed reality simulation with nurse anesthesia students",2020,"Informatics","7","4","7040040","","",,4,"10.3390/INFORMATICS7040040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094923423&doi=10.3390%2fINFORMATICS7040040&partnerID=40&md5=ef2c44c7d3a0e1e73d1c3081073e8d61","Background: The occurrence of a fire when implementing anesthesia is a high-risk, low-frequency event. The operating room is a high-stakes environment that has no room for error. Mixed reality simulation may be a solution to better prepare healthcare professionals. The purpose of this quantitative, descriptive study was to evaluate the technical and non-technical skills of student registered nurse anesthetists (SRNAs) who participated in a mixed reality simulation of an operating room fire. Methods: Magic Leap OneTM augmented reality headsets were used by 32 student registered nurse anesthetists to simulate an emergent fire during a simulated tracheostomy procedure. Both technical and non-technical skills were evaluated by faculty members utilizing a checklist. Results: The SRNAs' overall mean technical skill performance was 18.161.44 out of a maximum score of 20, and the mean non-technical skill performance was 91.25% out of 100%. Conclusions: This study demonstrated the utility and limitations in applying novel technology in simulation. Participants demonstrated a strong performance of technical and non-technical skills in the management of a simulated operating room fire. Recommendations for future applications include the use of multiple sensory inputs into the scenario design and including all core team members in the immersive mixed reality environment. © 2020 MDPI Multidisciplinary Digital Publishing Institute. All rights reserved.",,,"English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85094923423
"Sepasgozar S.M.E.","55924332100;","Digital twin and web-based virtual gaming technologies for online education: A case of construction management and engineering",2020,"Applied Sciences (Switzerland)","10","13","4678","","",,78,"10.3390/app10134678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087914094&doi=10.3390%2fapp10134678&partnerID=40&md5=1e21c318dbba588644855a8466362308","Mixed reality is advancing exponentially in some innovative industries, includingmanufacturing and aerospace. However, advanced applications of these technologies in architecture, engineering, and construction (AEC) businesses remain nascent. While it is in demand, the use of these technologies in developing the AEC digital pedagogy and for improving professional competence have received little attention. This paper presents a set of five novel digital technologies utilising virtual and augmented reality and digital twin, which adds value to the literature by showing their usefulness in the delivery of construction courses. The project involved designing, developing, and implementing a construction augmented reality (AR), including Piling AR (PAR) and a virtual tunnel boring machine (VTBM) module. The PAR is a smartphone module that presents different elements of a building structure, the footing system, and required equipment for footing construction. VTBM is developed as a multiplayer and avatar-included module for experiencing mechanisms of a tunnel boring machine. The novelty of this project is that it developed innovative immersive construction modules, practices of implementing digital pedagogy, and presenting the capacity of virtual technologies for education. This paper is also highly valuable to educators since it shows how a set of simple to complex technologies can be used for teaching various courses from a distance, either in emergencies such as corona virus disease (COVID-19) or as a part of regular teaching. This paper is a step forward to designing future practices full of virtual education appropriate to the new generation of digitally savvy students. © 2020 by the author.",,"SEIF 2018-2019; ","English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85087914094
"Laciok V., Bernatik A., Lesnak M.","57190938937;13205532400;6506784452;","Experimental implementation of new technology into the area of teaching occupational safety for industry 4.0",2020,"International Journal of Safety and Security Engineering","10","3",,"403","407",,9,"10.18280/ijsse.100313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088272732&doi=10.18280%2fijsse.100313&partnerID=40&md5=55ab972629c399d6b2a48ee797f1624f","The use of new technologies (additive technology, collaborative robotics, virtual or augmented reality) in teaching and preparing for it gives the teacher many different ways to activate students to learn. Therefore, this article focuses on the options for using virtual reality in the field of occupational safety. A work injury scenario was created in the XVR software environment. It was aimed at students studying Occupational and Process Safety at the Faculty of Safety Engineering (FSE), VSB-Technical University of Ostrava. In the future, they will be professionally qualified in risk prevention (Health, Safety, Environment Professional, HSE). The aim was to train students in: an employer's obligations during a work injury, the HSE Professional's job during a work injury, cooperating with the emergency services and the Czech Police. © 2020 WITPress. All rights reserved.","Accident prevention; Additives; Augmented reality; Emergency services; Engineering education; Health risks; Industry 4.0; Students; Additive technology; Occupational safety; Ostrava; Process safety; Risk prevention; Software environments; Technical universities; Occupational risks; experimental study; innovation; occupation; risk assessment; software; student; teaching; technological development; virtual reality; Czech Republic; Moravskoslezsky; Ostrava",,"English",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85088272732
"Liu Z., Wang X., Cai Y., Xu W., Liu Q., Zhou Z., Pham D.T.","57202399533;57214220881;57214225701;57221159460;55577742400;55538054700;7203009688;","Dynamic risk assessment and active response strategy for industrial human-robot collaboration",2020,"Computers and Industrial Engineering","141",,"106302","","",,28,"10.1016/j.cie.2020.106302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078452968&doi=10.1016%2fj.cie.2020.106302&partnerID=40&md5=d29fd256c7c66ea3a855ac356475e02b","To enhance flexibility and sustainability, human-robot collaboration is becoming a major feature of next-generation robots. The safety assessment strategy is the first and crucial issue that needs to be considered due to the removal of the safety barrier. This paper determined the set of safety indicators and established an assessment model based on the latest safety-related ISO standards and manufacturing conditions. A dynamic modified SSM (speed and separation monitoring) method is presented for ensuring the safety of human-robot collaboration while maintaining productivity as high as possible. A prototype system including dynamic risk assessment and safe motion control is developed based on the virtual model of the robot and human skeleton point data from the vision sensor. The real-time risk status of the working robot can be known and the risk field around the robot which is visualized in an augmented reality environment so as to ensure safe human-robot collaboration. This system is experimentally validated on a human-robot collaboration cell using an industrial robot with six degrees of freedom. © 2020 Elsevier Ltd","Augmented reality; Degrees of freedom (mechanics); ISO Standards; Risk assessment; Safety engineering; Sustainable development; Virtual reality; Visual servoing; Dynamic risk assessments; Human-robot collaboration; Manufacturing conditions; Next generation robots; Response strategies; Risk visualization; Safety assessments; Six degrees of freedom; Robots","EP/N018524/1; 51675389, 51775399","English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85078452968
"Wazir W., Khattak H.A., Almogren A., Khan M.A., Ud Din I.","57214084042;57208818911;8970033500;57188818515;55428202900;","Doodle-Based Authentication Technique Using Augmented Reality",2020,"IEEE Access","8",,"8947984","4022","4034",,12,"10.1109/ACCESS.2019.2963543","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078202399&doi=10.1109%2fACCESS.2019.2963543&partnerID=40&md5=7cf0f296e0d3e2ca00c9da6ae1a0b892","The emergence of augmented reality (AR) and virtual reality (VR) has revolutionized the trends in computing devices and modern technologies drastically. With this revolution, there is a need to extend existing architectures of security to serve as the key protective feature in all computing devices. In this experimental study, the aim is to develop a novel authentication technique with a fusion of graphical doodle password approach and AR environments. The mash-up of both doodle passwords and AR in a 3D space gives a promising direction to set off to a modern, more usable, and satisfying authentication techniques. The proposed approach works on real-time size and coordinate matching of doodles in an AR environment for the authentication of users. The creation of doodle passwords in an AR space is carried on by touch-gesture-recognition on a smartphone. The usability and usefulness of the proposed technique is evaluated by conducting an extensive survey, based on tasks and user experience assessments. The randomized-post-test-only study model is used to conduct experimentation that is also followed by the analysis of security parameters with the help of confusion matrix. The obtained results predict the use of AR during the authentication process more satisfying for users, where the proposed technique is useful, usable, and secure in comparison to the existing authentication approaches. This paper also highlights the importance of research needed for the utilization of modern techniques during the creation of security frameworks. © 2013 IEEE.","Augmented reality; Gesture recognition; Network security; Virtual reality; Authentication techniques; Coordinate matching; Existing architectures; Modern technologies; password; Security frameworks; Usable security; User experience assessments; Authentication","","English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85078202399
"Ottogalli K., Rosquete D., Amundarain A., Aguinaga I., Borro D.","57204824180;57204824331;6507321406;18433619200;6507510737;","Flexible framework to model industry 4.0 processes for virtual simulators",2019,"Applied Sciences (Switzerland)","9","23","4983","","",,20,"10.3390/app9234983","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076497693&doi=10.3390%2fapp9234983&partnerID=40&md5=f155424920f57e459cfe8a1de9751629","Virtual reality (VR)- and augmented reality (AR)-based simulations are key technologies in Industry 4.0 which allow for testing and studying of new processes before their deployment. A simulator of industrial processes needs a flexible way in which to model the activities performed by the worker and other elements involved, such as robots and machinery. This work proposes a framework to model industrial processes for VR and AR simulators. The desk method was used to review previous research and extract the most important features of current approaches. Novel features include interaction among human workers and a variety of automation systems, such as collaborative robots, a broader set of tasks (including assembly and disassembly of components), flexibility of modeling industrial processes for different domains and purposes, a clear separation of process definition and simulator, and independence of specific programming languages or technologies. Three industrial scenarios modeled with this framework are presented: an aircraft assembly scenario, a guidance tool for high-voltage cell security, and an application for the training of machine-tool usage. © 2019 by the authors.",,"737881; ","English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85076497693
"Singla S., Aswath S., Bhatt V.K., Sharma B.K., Pal V.K.","57210291644;57210288660;57209512115;57207889762;57209503585;","Virtual reality in non-communicable diseases",2019,"International Journal of Innovative Technology and Exploring Engineering","9","1",,"1325","1333",,,"10.35940/ijitee.L3709.119119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075118566&doi=10.35940%2fijitee.L3709.119119&partnerID=40&md5=76ef4765ee81135fbdcbf6779c3ccd7d","Virtual Reality (VR) is often associated with the gaming business, the advancement isn't just about gaming. Increased reality has been around for quite a while now and there have been new VR applications in different fields. It is ordinary that in excess of 500 million VR headsets will be sold always 2025 and the entire VR development would be worth over $30 billion consistently 2020. This gigantic advancement can't be solely from the gaming business, anyway, accounts from various industry zones which are viably using this impacting development. Virtual reality is utilized more in health care such as for learning skills, treatments, and robotic surgery. It is utilized with other medical tests like that of x-rays, scans to reduce the risk of surgery and understand the medical condition of the patient. A head-mounted device, both contracted HMD, is a presentation gadget, worn on the head or as a component of a protective cap, that has a little showcase optic before one or each eye. An HMD has numerous utilizations, incorporating into gaming, aeronautics, designing, and prescription lift. A head-mounted showcase is the essential part of computer-generated reality headsets. There is likewise an optical head-mounted presentation, which is a wearable showcase that can reflect anticipated pictures and enables a client to see through it. Human services are one such industry in which there are various utilizations of VR and the potential is open-finished. Medicinal experts and researchers have been at the planning phase creating and actualizing VR applications for quite a while now and have concocted of the most exceptional utilizations of VR in human services. Today, human services associations need to see how VR is changing social insurance and join best practices in their everyday tasks. Non-communicable disease (NCD) which are leading cause of death worldwide such as Diabetes, Cardiovascular disease, Alzheimer. Virtual reality is found to play a vital role in the NCD treatment. Recently, NHS England diabetes group has joined forces with Oxford Medical Simulation to prepare specialists utilizing computer generated reality. Specialists would now be able to rehearse in augmented reality restorative crises, to improve care for patients with diabetes. © 2019, Blue Eyes Intelligence Engineering and Sciences Publication. All rights reserved.",,,"English",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85075118566
"Damala A., Ruthven I., Hornecker E.","17434088200;6603708900;13006172500;","The MUSETECH model: A comprehensive evaluation framework for museum technology",2019,"Journal on Computing and Cultural Heritage","12","1","7","","",,20,"10.1145/3297717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062335863&doi=10.1145%2f3297717&partnerID=40&md5=fb1c27fa75bdd333ad98b5a2dcadb20f","Digital technologies are being introduced in museums and other informal learning environments alongside more traditional interpretive and communication media. An increasing number of studies has proved the potential of digitally mediated cultural heritage experiences. However, there is still a lot of controversy as to the advantages and disadvantages of introducing the digital into museum settings, primarily related to the risks and investment in terms of time and human and financial resources required. This work introduces the MUSETECH model, a comprehensive framework for evaluating museum technology before and after its introduction into a museum setting. One of the unique features of our framework is to consider the evaluation of digital technologies from three different perspectives: the cultural heritage professional, cultural heritage institution, and museum visitor. The framework benefited from an extensive review of the current state of the art and from inputs from cultural heritage professionals, designers, and engineers. MUSETECH can be used as a tool for reflection before, during, and after introducing novel digital media resources. The model covers technologies as diverse as mobile museum guides, Augmented and Virtual Reality applications, hands-on museum interactives, edutainment applications, digitally mediated tangible and embodied experiences, or online approaches used for museum education and learning. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Digital storage; Museums; User interfaces; Virtual reality; Cultural heritages; Digital heritage; Evaluation; Interaction design; Interactivity; Usability; User experience; Computer aided instruction","600851-meSch; 600851; ","English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85062335863
"Shi Q., Lee C.","57188996217;13806509700;","Self-Powered Bio-Inspired Spider-Net-Coding Interface Using Single-Electrode Triboelectric Nanogenerator",2019,"Advanced Science","6","15","1900617","","",,101,"10.1002/advs.201900617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066464311&doi=10.1002%2fadvs.201900617&partnerID=40&md5=ca4f16c22a1ad553a5a7252d6d4861cf","Human–machine interfaces are essential components between various human and machine interactions such as entertainment, robotics control, smart home, virtual/augmented reality, etc. Recently, various triboelectric-based interfaces have been developed toward flexible wearable and battery-less applications. However, most of them exhibit complicated structures and a large number of electrodes for multidirectional control. Herein, a bio-inspired spider-net-coding (BISNC) interface with great flexibility, scalability, and single-electrode output is proposed, through connecting information-coding electrodes into a single triboelectric electrode. Two types of coding designs are investigated, i.e., information coding by large/small electrode width (L/S coding) and information coding with/without electrode at a predefined position (0/1 coding). The BISNC interface shows high scalability with a single electrode for detection and/or control of multiple directions, by detecting different output signal patterns. In addition, it also has excellent reliability and robustness in actual usage scenarios, since recognition of signal patterns is in regardless of absolute amplitude and thereby not affected by sliding speed/force, humidity, etc. Based on the spider-net-coding concept, single-electrode interfaces for multidirectional 3D control, security code systems, and flexible wearable electronics are successfully developed, indicating the great potentials of this technology in diversified applications such as human–machine interaction, virtual/augmented reality, security, robotics, Internet of Things, etc. © 2019 The Authors. Published by WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","Automation; Electrodes; Flexible electronics; Human robot interaction; Humidity control; Machine components; Nanogenerators; Nanotechnology; Pattern recognition systems; Robotics; Scalability; Triboelectricity; Virtual reality; Wearable technology; Complicated structures; High scalabilities; Information coding; Machine interfaces; Pre-defined position; Reliability and robustness; Self-powered; Single electrodes; Codes (symbols)","R-263-000-C91-305","English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85066464311
"Lee M., Kim H., Paik J.","57202494260;56369599600;7102939640;","Correction of Barrel Distortion in Fisheye Lens Images Using Image-Based Estimation of Distortion Parameters",2019,"IEEE Access","7",,"8678625","45723","45733",,17,"10.1109/ACCESS.2019.2908451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064614618&doi=10.1109%2fACCESS.2019.2908451&partnerID=40&md5=bc486fee42779bfa2554bdbe9e2f1245","Images acquired by a fisheye lens camera contain geometric distortion that results in deformation of the object's shape. To correct the lens distortion, existing methods use prior information, such as calibration patterns or lens design specifications. However, the use of a calibration pattern works only when an input scene is a 2-D plane at a prespecified position. On the other hand, the lens design specifications can be understood only by optical experts. To solve these problems, we present a novel image-based algorithm that corrects the geometric distortion. The proposed algorithm consists of three stages: i) feature detection, ii) distortion parameter estimation, and iii) selection of the optimally corrected image out of multiple corrected candidates. The proposed method can automatically select the optimal amount of correction for a fisheye lens distortion by analyzing characteristics of the distorted image using neither prespecified lens design parameters nor calibration patterns. Furthermore, our method performs not only on-line correction by using facial landmark points, but also off-line correction described in subsection III-C. As a result, the proposed method can be applied to a virtual reality (VR) or augmented reality (AR) camera with two fisheye lenses in a field-of-view (FOV) of 195°, autonomous vehicle vision systems, wide-area visual surveillance systems, and unmanned aerial vehicle (UAV) cameras. © 2013 IEEE.","Antennas; Augmented reality; Autonomous vehicles; Calibration; Cameras; Geometry; Optical instrument lenses; Security systems; Specifications; Unmanned aerial vehicles (UAV); Virtual reality; Distortion parameters; Facial landmark; Fish-eye lens; Geometric distortion; Lens distortion correction; Parameter estimation","2017-0-00250; 2014-0-00077","English",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85064614618
"Royakkers L., Timmer J., Kool L., van Est R.","6506230746;56727759600;24402504500;35758095400;","Societal and ethical issues of digitization",2018,"Ethics and Information Technology","20","2",,"127","142",,117,"10.1007/s10676-018-9452-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044087398&doi=10.1007%2fs10676-018-9452-x&partnerID=40&md5=5a5dc26ca09f77839e4d7038ad46d870","In this paper we discuss the social and ethical issues that arise as a result of digitization based on six dominant technologies: Internet of Things, robotics, biometrics, persuasive technology, virtual & augmented reality, and digital platforms. We highlight the many developments in the digitizing society that appear to be at odds with six recurring themes revealing from our analysis of the scientific literature on the dominant technologies: privacy, autonomy, security, human dignity, justice, and balance of power. This study shows that the new wave of digitization is putting pressure on these public values. In order to effectively shape the digital society in a socially and ethically responsible way, stakeholders need to have a clear understanding of what such issues might be. Supervision has been developed the most in the areas of privacy and data protection. For other ethical issues concerning digitization such as discrimination, autonomy, human dignity and unequal balance of power, the supervision is not as well organized. © 2018, The Author(s).","Analog to digital conversion; Augmented reality; Security of data; Digital platforms; Digital society; Ethical issues; Ethics; Persuasive technology; Public values; Scientific literature; Philosophical aspects",,"English",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85044087398
"Metcalf M., Rossie K., Stokes K., Tallman C., Tanner B.","7007179512;57676596800;57202291217;57202279192;57189203510;","Virtual reality cue refusal video game for alcohol and cigarette recovery support: Summative study",2018,"JMIR Serious Games","20","4","e7","","",,17,"10.2196/games.9231","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047779794&doi=10.2196%2fgames.9231&partnerID=40&md5=c22f452180453738d137fc4747cc77da","Background: New technologies such as virtual reality, augmented reality, and video games hold promise to support and enhance individuals in addiction treatment and recovery. Quitting or decreasing cigarette or alcohol use can lead to significant health improvements for individuals, decreasing heart disease risk and cancer risks (for both nicotine and alcohol use), among others. However, remaining in recovery from use is a significant challenge for most individuals. Objective: We developed and assessed the Take Control game, a partially immersive Kinect for Windows platform game that allows users to counter substance cues through active movements (hitting, kicking, etc). Methods: Formative analysis during phase I and phase II guided development. We conducted a small wait-list control trial using a quasi-random sampling technique (systematic) with 61 participants in recovery from addiction to alcohol or tobacco. Participants used the game 3 times and reported on substance use, cravings, satisfaction with the game experience, self-efficacy related to recovery, and side effects from exposure to a virtual reality intervention and substance cues. Results: Participants found the game engaging and fun and felt playing the game would support recovery efforts. On average, reported substance use decreased for participants during the intervention period. Participants in recovery for alcohol use saw more benefit than those in recovery for tobacco use, with a statistically significant increase in self-efficacy, attitude, and behavior during the intervention. Side effects from the use of a virtual reality intervention were minor and decreased over time; cravings and side effects also decreased during the study. Conclusions: The preliminary results suggest the intervention holds promise as an adjunct to standard treatment for those in recovery, particularly from alcohol use. © Mary Metcalf, Karen Rossie, Katie Stokes, Christina Tallman, Bradley Tanner.",,"HHSN2712013000041C; ","English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85047779794
"Kumar D., González A., Das A., Dutta A., Fraisse P., Hayashibe M., Lahiri U.","57201040710;57188772508;35558233300;37080501000;35589724100;6602744530;35119157400;","Virtual reality-based center of mass-assisted personalized balance training system",2018,"Frontiers in Bioengineering and Biotechnology","5","JAN","85","","",,8,"10.3389/fbioe.2017.00085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041354434&doi=10.3389%2ffbioe.2017.00085&partnerID=40&md5=2783ea10f806d880908f63bb10ee118a","Poststroke hemiplegic patients often show altered weight distribution with balance disorders, increasing their risk of fall. Conventional balance training, though powerful, suffers from scarcity of trained therapists, frequent visits to clinics to get therapy, one-on-one therapy sessions, and monotony of repetitive exercise tasks. Thus, technology-assisted balance rehabilitation can be an alternative solution. Here, we chose virtual reality as a technology-based platform to develop motivating balance tasks. This platform was augmented with off-the-shelf available sensors such as Nintendo Wii balance board and Kinect to estimate one's center of mass (CoM). The virtual reality-based CoM-assisted balance tasks (Virtual CoMBaT) was designed to be adaptive to one's individualized weight-shifting capability quantified through CoM displacement. Participants were asked to interact with Virtual CoMBaT that offered tasks of varying challenge levels while adhering to ankle strategy for weight shifting. To facilitate the patients to use ankle strategy during weight-shifting, we designed a heel lift detection module. A usability study was carried out with 12 hemiplegic patients. Results indicate the potential of our system to contribute to improving one's overall performance in balance-related tasks belonging to different difficulty levels. © 2018 Kumar, González, Das, Dutta, Fraisse, Hayashibe and Lahiri.","E-learning; Interactive computer graphics; Ankle strategies; Balance rehabilitations; Center of mass; Kinect; Stroke; Virtual reality",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85041354434
"Alam M.F., Katsikas S., Beltramello O., Hadjiefthymiades S.","57061419000;54939590000;57206137363;6603881052;","Augmented and virtual reality based monitoring and safety system: A prototype IoT platform",2017,"Journal of Network and Computer Applications","89",,,"109","119",,61,"10.1016/j.jnca.2017.03.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016438031&doi=10.1016%2fj.jnca.2017.03.022&partnerID=40&md5=fd03a592a947579fdc656ace6be24708","This paper presents an Augmented and Virtual Reality (AR/VR) based IoT prototype system. Performing maintenance tasks in a complex environment is quite challenging and difficult due to complex, and possibly, underground facilities, uneasy access, human factors, heavy machineries, etc. Current technology is not acceptable because of significant delays in communication and data transmission, missing multi-input interfaces, and simultaneous supervision of multiple workers who are working in the extreme environment. The aim is to technically advance and combine several technologies and integrate them as integral part of a personnel safety system to improve safety, maintain availability, reduce errors and decrease the time needed for scheduled or ad hoc interventions. We emphasize on the aspects that were made “feasible” on the worker's side due to the equipment used (mobile computing equipment). We present that the demanding tasks that previously were simply undertaken on the fixed infrastructure are now possible on the mobile end. The research challenges lie in the development of real-time data-transmission, instantaneous analysis of data coming from different inputs, local intelligence in low power embedded systems, interaction with multiple on-site users, complex user interfaces, portability and wearability. This work is part EDUSAFE, a Marie Curie ITN (Initial Training Network) project focusing on research into the use of Augmented and Virtual Reality (AR/VR) during planned and ad hoc maintenance in extreme work environments. © 2017 Elsevier Ltd","Complex networks; Data communication systems; Data transfer; Embedded systems; Machinery; Maintenance; Real time systems; Safety engineering; Security systems; User interfaces; Virtual reality; Augmented and virtual realities; Low power embedded systems; Mobile; Modular; Performing maintenance; Personnel safety systems; Prototype; Real time data transmission; Internet of things","645220; 316919, PITN-GA-2012–316919-EDUSAFE","English",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85016438031
"Tuma Z., Kotek L., Tuma J., Bradac F.","57133179500;55322068500;57162690200;56067279500;","Application of augmented reality for verification of real workplace state",2016,"MM Science Journal","2016","NOVEMBER",,"1487","1490",,3,"10.17973/MMSJ.2016_11_2016166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995581852&doi=10.17973%2fMMSJ.2016_11_2016166&partnerID=40&md5=fa9f4dc445d2b50b8e32214ce259c172","The article is aimed at verifying the state of a real workplace using virtual reality. In analyzing the readiness of virtual reality applications, augmented reality was selected for the following work. The most significant advantage of augmented reality is the implementation of a virtual model and the ability to deal with the analysis in a real environment, which is particularly beneficial in the case of production plants. In the first phase of the work, an analysis of the current state of the workplace was carried out, where the requirements for the design of the new workplace were specified. This was followed by the phase of design preparation in 3D modeller. At this very stage it appeared to be advantageous to use virtual reality applications; in the design process, regular approval procedures are required as for an expert team (management, design, quality,. ..), which puts high qualification requirements on the readiness of this team. In this phase, the 3D design of the new workplace was inserted into the application supported by augmented reality and some options were indicated to deal with the ergonomic and risk analysis. The result of this work is, in particular, an extension of options in designing and analyzing production workplaces and machinery in multidisciplinary teams. © 2016, MM publishing Ltd. All rights reserved.",,,"English",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-84995581852
"Rosen J.M., Kun L., Mosher R.E., Grigg E., Merrell R.C., Macedonia C., Klaudt-Moreau J., Price-Smith A., Geiling J.","36191106800;7103113161;25645128000;6602589753;7006138572;6602190405;57190063253;6507462603;6602533666;","Cybercare 2.0: meeting the challenge of the global burden of disease in 2030",2016,"Health and Technology","6","1",,"35","51",,13,"10.1007/s12553-016-0132-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977083347&doi=10.1007%2fs12553-016-0132-8&partnerID=40&md5=70d1aea0673bce2eb1a466c30167853b","In this paper, we propose to advance and transform today’s healthcare system using a model of networked health care called Cybercare. Cybercare means “health care in cyberspace” — for example, doctors consulting with patients via videoconferencing across a distributed network; or patients receiving care locally — in neighborhoods, “minute clinics,” and homes — using information technologies such as telemedicine, smartphones, and wearable sensors to link to tertiary medical specialists. This model contrasts with traditional health care, in which patients travel (often a great distance) to receive care from providers in a central hospital. The Cybercare model shifts health care provision from hospital to home; from specialist to generalist; and from treatment to prevention. Cybercare employs advanced technology to deliver services efficiently across the distributed network — for example, using telemedicine, wearable sensors and cell phones to link patients to specialists and upload their medical data in near-real time; using information technology (IT) to rapidly detect, track, and contain the spread of a global pandemic; or using cell phones to manage medical care in a disaster situation. Cybercare uses seven “pillars” of technology to provide medical care: genomics; telemedicine; robotics; simulation, including virtual and augmented reality; artificial intelligence (AI), including intelligent agents; the electronic medical record (EMR); and smartphones. All these technologies are evolving and blending. The technologies are integrated functionally because they underlie the Cybercare network, and/or form part of the care for patients using that distributed network. Moving health care provision to a networked, distributed model will save money, improve outcomes, facilitate access, improve security, increase patient and provider satisfaction, and may mitigate the international global burden of disease. In this paper we discuss how Cybercare is being implemented now, and envision its growth by 2030. © 2016, The Author(s).","Article; artificial intelligence; augmented reality; chronic disease; communicable disease; contact examination; cybercare; cybernetics; developed country; Ebola hemorrhagic fever; electronic medical record; genomics; health care; health care policy; health education; home care; hospital care; human; information dissemination; medical care; medical informatics; medical specialist; migration; mobile phone; non communicable disease; population growth; robotics; sensor; smartphone; teleconsultation; telemedicine; videoconferencing; virtual reality; wearable sensor",,"English",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-84977083347
"Hsu K.-S., Wang C.-S., Jiang J.-F., Wei H.-Y.","24921329200;55174951200;50561695300;50562381400;","Development of a Real-Time Detection System for Augmented Reality Driving",2015,"Mathematical Problems in Engineering","2015",,"913408","","",,4,"10.1155/2015/913408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946088038&doi=10.1155%2f2015%2f913408&partnerID=40&md5=37e31758f110339f3fa6a379af3627db","Augmented reality technology is applied so that driving tests may be performed in various environments using a virtual reality scenario with the ultimate goal of improving visual and interactive effects of simulated drivers. Environmental conditions simulating a real scenario are created using an augmented reality structure, which guarantees the test taker's security since they are not subject to real-life elements and dangers. Furthermore, the accuracy of tests conducted through virtual reality is not influenced by either environmental or human factors. Driver posture is captured in real time using Kinect's depth perception function and then applied to driving simulation effects that are emulated by Unity3D's gaming technology. Subsequently, different driving models may be collected through different drivers. In this research, nearly true and realistic street environments are simulated to evaluate driver behavior. A variety of different visual effects are easily available to effectively reduce error rates, thereby significantly improving test security as well as the reliability and reality of this project. Different situation designs are simulated and evaluated to increase development efficiency and build more security verification test platforms using such technology in conjunction with driving tests, vehicle fittings, environmental factors, and so forth. © 2015 Kuei-Shu Hsu et al.","Augmented reality; Behavioral research; Depth perception; Environmental technology; Virtual reality; Augmented reality technology; Driving simulation; Environmental conditions; Environmental factors; Gaming technology; Interactive effect; Real-time detection; Security verification; Automobile testing",,"English",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-84946088038
